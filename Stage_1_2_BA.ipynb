{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreloading if import packages are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import utils\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "\n",
    "PROJECT_DIR = os.getcwd()\n",
    "\n",
    "# Editable part\n",
    "dataset_name = \"boot_stage2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self, PROJECT_DIR, dataset_name, dataset_info):\n",
    "        self.project_dir = PROJECT_DIR\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset_info = dataset_info\n",
    "        self.quick_save_reset()\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        txt_observation = utils.read_txt(os.path.join(self.project_dir, \"dataset\", self.dataset_name, \"observation.txt\"))\n",
    "        txt_camera_id = utils.read_txt(os.path.join(self.project_dir, \"dataset\", self.dataset_name, \"camera_id.txt\"))\n",
    "\n",
    "        data_observation = np.array([i.strip().split(\",\") for i in txt_observation], dtype=float)\n",
    "        self.data_camera_id = np.array([i.strip().split(\",\") for i in txt_camera_id], dtype=int)\n",
    "        self.camera_indices = data_observation[:, 0].astype(int)\n",
    "        self.point_indices = data_observation[:, 1].astype(int)\n",
    "        self.points_2d = data_observation[:, 2:]\n",
    "        self.points_3d = np.zeros((len(np.unique(self.point_indices)), 3))\n",
    "        self.camera_extrinsics = np.array([np.eye(4) for i in range(self.camera_indices.max() + 1)])\n",
    "        self.camera_intrinsic = np.array(self.dataset_info[\"parameters\"][\"camera\"][\"intrinsics\"])\n",
    "\n",
    "    def get(self):\n",
    "        return self.data_camera_id, self.camera_indices, self.point_indices, self.points_2d, self.points_3d, self.camera_extrinsics, self.camera_intrinsic\n",
    "\n",
    "    def set_point_3d(self, idx, p3):\n",
    "        self.points_3d[idx] = np.array(p3[:3])\n",
    "\n",
    "    def set_camera_ext(self, idx, cam44):\n",
    "        self.camera_extrinsics[idx] = np.array(cam44[:4, :4])\n",
    "\n",
    "    def get_camera_ext(self, idx):\n",
    "        return self.camera_extrinsics[idx]\n",
    "\n",
    "    def find_same_points_idx(self, img_src, img_tar):\n",
    "        img1_pts = self.point_indices[self.camera_indices == img_src] \n",
    "        img2_pts = self.point_indices[self.camera_indices == img_tar] \n",
    "        intersection = list(set(img1_pts) & set(img2_pts))\n",
    "        return intersection\n",
    "    \n",
    "    def find_same_points_2d(self, img_src, img_tar):\n",
    "        its = self.find_same_points_idx(img_src, img_tar)\n",
    "        indexes = np.arange(len(self.point_indices))\n",
    "        idx_left = np.array([list(set(indexes[self.camera_indices == img_src]) & set(indexes[self.point_indices == pt_idx])) for pt_idx in its]).reshape(-1)\n",
    "        idx_right = np.array([list(set(indexes[self.camera_indices == img_tar]) & set(indexes[self.point_indices == pt_idx])) for pt_idx in its]).reshape(-1)\n",
    "\n",
    "        # idx_left =  [np.where(self.point_indices[self.camera_indices == img_src] == idx)[0][0] for idx in its]\n",
    "        # idx_right = [np.where(self.point_indices[self.camera_indices == img_tar] == idx)[0][0] for idx in its]\n",
    "        return self.points_2d[idx_left], self.points_2d[idx_right]\n",
    "\n",
    "    def find_highest_correspondences(self, img_idx, exclude=[]):\n",
    "        correspondences_count = []\n",
    "        for i in range(len(self.camera_extrinsics)):\n",
    "            if (i == img_idx) or (i in exclude):\n",
    "                correspondences_count.append(0) #skip\n",
    "                continue\n",
    "            correspondences_count.append(len(self.find_same_points_idx(img_idx, i)))\n",
    "        return np.argmax(correspondences_count), correspondences_count\n",
    "    \n",
    "    def quick_save_reset(self):\n",
    "        self.quick_save_record_idx = 0\n",
    "        self.quick_save_campts_record_idx = 0\n",
    "    \n",
    "    def quick_save_data(self, params, num_run):\n",
    "        savedir = os.path.join(self.project_dir, \"dataset\", self.dataset_name, \"result\", f\"run{num_run}\")\n",
    "        if not os.path.exists(savedir):\n",
    "            os.makedirs(savedir)\n",
    "\n",
    "        savefile = os.path.join(savedir, f\"record_{self.quick_save_record_idx}.txt\")\n",
    "        with open(savefile, 'w') as f:\n",
    "            f.write(params)\n",
    "        self.quick_save_record_idx += 1\n",
    "\n",
    "    def quick_save_camera_and_pts3d(self, json_data, num_run):\n",
    "        savedir = os.path.join(self.project_dir, \"dataset\", self.dataset_name, \"result\", f\"run{num_run}\")\n",
    "        if not os.path.exists(savedir):\n",
    "            os.makedirs(savedir)\n",
    "\n",
    "        savefile = os.path.join(savedir, f\"record_{self.quick_save_campts_record_idx}.json\")\n",
    "        utils.export_json(savefile, json_data)\n",
    "        self.quick_save_campts_record_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = utils.get_dataset_info(dataset_name, PROJECT_DIR)\n",
    "dataset_info[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = DataManager(PROJECT_DIR, dataset_name, dataset_info)\n",
    "data_camera_id, camera_indices, point_indices, points_2d, points_3d, camera_extrinsics, camera_intrinsic = data_manager.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv0, uv1 = data_manager.find_same_points_2d(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = dataset_info[\"data\"][\"image\"]\n",
    "img1 = cv2.imread(os.path.join(img_dir, \"00000.jpg\"))\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "# img2 = cv2.imread(os.path.join(img_dir, \"00028.jpg\"))\n",
    "# img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img_draw1 = img1.copy()#np.hstack((img1, img2)).copy()\n",
    "img_draw2 = img2.copy()#np.hstack((img1, img2)).copy()\n",
    "\n",
    "uv_gt1, uv_gt2 = data_manager.find_same_points_2d(0, 1)\n",
    "\n",
    "for ((u1, v1), (u2, v2)) in zip(uv_gt1, uv_gt2):\n",
    "    cv2.circle(img_draw1, (int(u1), int(v1)), 1, (0, 255, 0), 10)\n",
    "    # cv2.circle(img_draw2, (int(u2), int(v2)), 1, (255, 0, 0), 10)\n",
    "\n",
    "for ((u1, v1), (u2, v2)) in zip(uv_gt1, uv_gt2):\n",
    "    cv2.line(img_draw1, (int(u1), int(v1)), (int(u2), int(v2)), (255, 255, 0), 2) \n",
    "    cv2.circle(img_draw1, (int(u2), int(v2)), 1, (255, 0, 0), 10)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(25, 15))\n",
    "plt.imshow(img_draw1)\n",
    "# plt.figure(figsize=(25, 15))\n",
    "# plt.imshow(img_draw2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Tools definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tools:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def reproject_ray(intrinsic, extrinsic, uv):\n",
    "        # extract oriagin and direction\n",
    "        origin = extrinsic[:3, 3]\n",
    "        fx, fy, cx, cy = intrinsic[0, 0], intrinsic[1, 1], intrinsic[0, 2], intrinsic[1, 2]\n",
    "        norm_coor = np.array([(uv[0] - cx) / fx, - (uv[1] - cy) / fy, 1])\n",
    "        direction = extrinsic[:3, :3].dot(norm_coor / np.linalg.norm(norm_coor))\n",
    "        return origin, direction\n",
    "\n",
    "    @staticmethod\n",
    "    def reproject_uvs(cam_int, cam_ext, pts_3d):\n",
    "        cam_ext_inv = cam_ext.copy()\n",
    "        # cam_ext_inv[:3, :3] = cam_ext_inv[:3, :3].T\n",
    "        inv_proj = np.linalg.inv(cam_ext_inv)\n",
    "        uvs = [Tools.reproject_uv(cam_int, inv_proj, pt, True) for pt in pts_3d]\n",
    "        return uvs      \n",
    "\n",
    "    @staticmethod\n",
    "    def reproject_uv(cam_intrinsic, cam_extrinsic, pt_3d, is_extrinsic_inverted=False):\n",
    "        cam_extrinsic_inv = cam_extrinsic.copy()\n",
    "        if not is_extrinsic_inverted:\n",
    "            # inverse extrinsic to project\n",
    "            # cam_extrinsic_inv[:3, :3] = cam_extrinsic_inv[:3, :3].T\n",
    "            cam_extrinsic_inv = np.linalg.inv(cam_extrinsic_inv)\n",
    "\n",
    "        # project to screen\n",
    "        pt_uv = cam_intrinsic.dot(cam_extrinsic_inv.dot(np.array([pt_3d[0], pt_3d[1], pt_3d[2], 1]))[:3])\n",
    "        pt_uv = pt_uv/pt_uv[2]\n",
    "\n",
    "        # if flipping y true\n",
    "        flip_y = True\n",
    "        if flip_y:\n",
    "            pt_uv[1] = 2 * cam_intrinsic[1, 2] - pt_uv[1]\n",
    "        return pt_uv[:2]\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_3d_from_2_cameras(cam_int, cam_ext_src, cam_ext_tar, uv_src, uv_tar, include_dist=False):\n",
    "        pts_3d, dists = [], []\n",
    "        for uv_1, uv_2 in zip(uv_src, uv_tar):\n",
    "            p0, d0 = Tools.reproject_ray(intrinsic=cam_int, extrinsic=cam_ext_src, uv=uv_1)\n",
    "            p1, d1 = Tools.reproject_ray(intrinsic=cam_int, extrinsic=cam_ext_tar, uv=uv_2)\n",
    "            pts, dist = utils.triangulate_point(p0, p1, d0, d1)\n",
    "            dists.append(dist)\n",
    "            pts_3d.append(pts)\n",
    "        return np.array(pts_3d), dists if include_dist else None\n",
    "\n",
    "    @staticmethod\n",
    "    def recorrect_essential_matrix(cam_int, cam_ext_tar, uv_src, uv_tar):\n",
    "        # get screen limit\n",
    "        # screen_width  = 2 * cam_int[0, 2]\n",
    "        # screen_height = 2 * cam_int[1, 2]\n",
    "\n",
    "        # # generate 3d\n",
    "        # pts_3d = Tools.generate_3d_from_2_cameras(cam_int, cam_ext_src, cam_ext_tar, uv_src, uv_tar)\n",
    "\n",
    "        counts = []\n",
    "        for i in range(2):\n",
    "            cam_ext_new = cam_ext_tar.copy()\n",
    "            # modify translation\n",
    "            if i % 2 == 1:\n",
    "                cam_ext_new[:3, 3] = -cam_ext_new[:3, 3]\n",
    "            # modify rotation\n",
    "            # if i >= 2:\n",
    "            #     cam_ext_new[0, 0] = -cam_ext_new[0, 0]\n",
    "            #     cam_ext_new[1, 1] = -cam_ext_new[1, 1]\n",
    "\n",
    "            # generate 3d\n",
    "            pts_3d = Tools.generate_3d_from_2_cameras(cam_int, np.eye(4), cam_ext_new, uv_src, uv_tar)[0]\n",
    "            pts_3d_cam2 = np.array([np.linalg.inv(cam_ext_new).dot(np.array([p[0], p[1], p[2], 1]))[:3] for p in pts_3d])\n",
    "            pts_positive_depth = [pt[2] >= 0 for pt in pts_3d]\n",
    "            pts_positive_depth_cam2 = [pt[2] >= 0 for pt in pts_3d_cam2]\n",
    "            \n",
    "            counts.append(np.sum(pts_positive_depth) + np.sum(pts_positive_depth_cam2))            \n",
    "        print(counts, np.argmax(counts))\n",
    "        out_cam_ext = cam_ext_tar.copy()\n",
    "        if np.argmax(counts) % 2 == 1:\n",
    "            out_cam_ext[:3, 3] = -out_cam_ext[:3, 3]\n",
    "        # if max(counts) >= 2:\n",
    "        #     out_cam_ext[0, 0] = -out_cam_ext[0, 0]\n",
    "        #     out_cam_ext[1, 1] = -out_cam_ext[1, 1]\n",
    "        return out_cam_ext\n",
    "        \n",
    "    # @staticmethod\n",
    "    # def reproject_uv(cam_intrinsic, cam_extrinsic, pt_3d, is_extrinsic_inverted=False):\n",
    "    #     cam_extrinsic_inv = cam_extrinsic.copy()\n",
    "    #     if not is_extrinsic_inverted:\n",
    "    #         # inverse extrinsic to project\n",
    "    #         cam_extrinsic_inv = cam_extrinsic.copy()\n",
    "    #         cam_extrinsic_inv[:3, :3] = cam_extrinsic_inv[:3, :3].T\n",
    "    #         cam_extrinsic_inv[:3, 3] = -cam_extrinsic_inv[:3, 3]\n",
    "\n",
    "    #     # project to screen\n",
    "    #     pt_uv = cam_intrinsic.dot(cam_extrinsic_inv.dot(np.array([pt_3d[0], pt_3d[1], pt_3d[2], 1]))[:3])\n",
    "    #     pt_uv = pt_uv/pt_uv[2]\n",
    "    #     return pt_uv[:2]\n",
    "    \n",
    "    # @staticmethod\n",
    "    # def reproject_uvs(cam_int, cam_ext, pts_3d):\n",
    "    #     inv_proj = np.array(cam_ext)\n",
    "    #     inv_proj[:3, :3] = inv_proj[:3, :3].T\n",
    "    #     inv_proj[:3, 3] = -inv_proj[:3, 3]\n",
    "\n",
    "    #     uvs = [Tools.reproject_uv(cam_int, inv_proj, pt, True) for pt in pts_3d]\n",
    "    #     return uvs      \n",
    "    \n",
    "    @staticmethod\n",
    "    def rotation_matrix_to_rodriguez(R):\n",
    "        # R = inv_proj_P2[:3, :3]\n",
    "        angle = np.arccos((np.trace(R) - 1) / 2) + 1.e-10\n",
    "        axis = 1 / (2 * np.sin(angle)) * np.array([R[2, 1] - R[1, 2], R[0, 2] - R[2, 0], R[1, 0] - R[0, 1]])\n",
    "\n",
    "        # Calculate Rodriguez rotation vector\n",
    "        rodriguez_vector = angle * axis\n",
    "        return rodriguez_vector\n",
    "\n",
    "    @staticmethod\n",
    "    def rodriguez_to_rotation_matrix(rodriguez_vector):\n",
    "        # Calculate angle of rotation and unit axis vector\n",
    "        angle = np.linalg.norm(rodriguez_vector)\n",
    "        axis = rodriguez_vector / angle if angle != 0 else np.array([0, 0, 0])\n",
    "\n",
    "        # Rodrigues' rotation formula\n",
    "        skew_symmetric = np.array([[0, -axis[2], axis[1]],\n",
    "                                [axis[2], 0, -axis[0]],\n",
    "                                [-axis[1], axis[0], 0]])\n",
    "        rotation_matrix = np.eye(3) + np.sin(angle) * skew_symmetric + (1 - np.cos(angle)) * np.dot(skew_symmetric, skew_symmetric)\n",
    "        return rotation_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tools_BundleAdjustment:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def estimate_essentials(camera_intrinsic, uv0, uv1):\n",
    "        E, mask = cv2.findEssentialMat(uv0, uv1,\n",
    "                                        method=cv2.RANSAC, \n",
    "                                        prob=0.999, \n",
    "                                        cameraMatrix=camera_intrinsic)\n",
    "\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(E)\n",
    "\n",
    "        # find the combinations\n",
    "        best_ext, cur_best = None, 0\n",
    "        for Ri in [R1, R2]:\n",
    "            for ti in [t, -t]:\n",
    "                # if ti[0] < 0:\n",
    "                #     continue\n",
    "                # ti = t if t[0] > 0 else -t\n",
    "                # ti = 0.3 * ti\n",
    "                ext = np.eye(4)\n",
    "                ext[:3, :3] = Ri.T\n",
    "                ext[:3, 3] = ti.reshape(-1)\n",
    "                try:\n",
    "                    pts_3d = Tools.generate_3d_from_2_cameras(camera_intrinsic, np.eye(4), ext, uv0, uv1)[0]\n",
    "                    pts_3d_cam2 = np.array([np.linalg.inv(ext).dot(np.array([p[0], p[1], p[2], 1]))[:3] for p in pts_3d])\n",
    "                except:\n",
    "                    continue\n",
    "                total = sum(pts_3d[:, 2] > 0) + sum(pts_3d_cam2[:, 2] > 0)\n",
    "                if(total > cur_best):\n",
    "                    best_ext = ext.copy()\n",
    "                    cur_best = total\n",
    "        return best_ext\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_route(data_manager, max_route=-1):\n",
    "        camera_indices = data_manager.get()[1]\n",
    "        img_indexes = np.unique(camera_indices)\n",
    "        # img_indexes_modified = np.append(img_indexes, img_indexes)[::2]\n",
    "        known_idx = [0]\n",
    "        extrinsics_from_essential = {}\n",
    "\n",
    "        # for each visited image idx, find the best option to take\n",
    "        while(len(known_idx) != len(img_indexes)):\n",
    "            best_idx_from = None\n",
    "            best_idx_to = None\n",
    "            best_corr_count = 0\n",
    "\n",
    "            # loop over visited image indexes, then check the highest but unchecked pairs\n",
    "            # for i, idx_l in enumerate(known_idx):\n",
    "            #     # correspondences from an image to all\n",
    "            #     corr_to_all = data_manager.find_highest_correspondences(idx_l)[1]\n",
    "            #     # then sort and loop over each entry to find whether it still has not yet calculated, max to min\n",
    "            #     corr_to_all_sorted = np.argsort(corr_to_all)[::-1]\n",
    "            #     for idx_r in corr_to_all_sorted:\n",
    "            #         # if already exist, no need to\n",
    "            #         if img_indexes[idx_r] in known_idx:\n",
    "            #             # print(\"skip\", idx_l, img_indexes[idx_r])\n",
    "            #             continue\n",
    "            #         if corr_to_all[idx_r] > best_corr_count:\n",
    "            #             best_idx_from = idx_l\n",
    "            #             best_idx_to = img_indexes[idx_r]\n",
    "            #             best_corr_count = corr_to_all[idx_r]\n",
    "            #             # print(\"best\", idx_l, img_indexes[idx_r])\n",
    "            #             break\n",
    "\n",
    "            best_idx_from = known_idx[-1]\n",
    "            best_idx_to = img_indexes[len(known_idx)]\n",
    "\n",
    "            # img_extrinsics[best_idx_to] = img_extrinsics[best_idx_from]\n",
    "            print(\"pose: \", best_idx_from, best_idx_to)\n",
    "            known_idx.append(best_idx_to)\n",
    "\n",
    "            img1_2d, img2_2d = data_manager.find_same_points_2d(best_idx_from, best_idx_to)\n",
    "\n",
    "            # lim_max = 540\n",
    "            # indexes = np.arange(len(img1_2d))\n",
    "            # mask = list(set(indexes[img1_2d[:, 1] < lim_max]) and set(indexes[img2_2d[:, 1] < lim_max]))\n",
    "            # img1_2d, img2_2d = img1_2d[mask], img2_2d[mask]\n",
    "            # new_ext = ExtrinsicMatrix.essential(pts1=img1_2d, pts2=img2_2d, intrinsic=camera_intrinsic, method=\"ransac\")\n",
    "            # new_ext = Tools.recorrect_essential_matrix(camera_intrinsic, new_ext, img1_2d, img2_2d)\n",
    "            new_ext = Tools_BundleAdjustment.estimate_essentials(data_manager.camera_intrinsic, img1_2d, img2_2d)\n",
    "\n",
    "            extrinsics_from_essential[str([best_idx_from, best_idx_to])] = new_ext\n",
    "            if not (max_route == -1):\n",
    "                if (len(known_idx) > 5):\n",
    "                    break\n",
    "        return extrinsics_from_essential\n",
    "    \n",
    "    @staticmethod\n",
    "    def rot_y_3x3(th):\n",
    "        th = np.deg2rad(th)\n",
    "        return np.array([[np.cos(th), 0, np.sin(th)], [0, 1, 0], [-np.sin(th), 0, np.cos(th)]])\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_ext(rot_y, pos):\n",
    "        ext = np.eye(4)\n",
    "        ext[:3, :3] = Tools_BundleAdjustment.rot_y_3x3(rot_y)\n",
    "        ext[:3, 3] = np.array(pos)\n",
    "        return ext\n",
    "\n",
    "    # @staticmethod\n",
    "    # def remap_point_3d(extrinsic_src, extrinsic_tar, pt_3d_src):\n",
    "    #     inv_ext_src = extrinsic_src.copy()\n",
    "    #     inv_ext_src[:3, :3] = inv_ext_src[:3, :3].T\n",
    "\n",
    "    #     pt_3d_h = np.ones(4)\n",
    "    #     pt_3d_h[:3] = pt_3d_src[:3]\n",
    "\n",
    "    #     ext_inv = extrinsic_tar.copy()\n",
    "    #     ext_inv[:3, :3] = ext_inv[:3, :3].T\n",
    "    #     ext_inv = np.linalg.inv(ext_inv)\n",
    "    #     return ext_inv.dot(inv_ext_src.dot(np.array(pt_3d_h)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(cam1_ext, cam2_ext, pt3d):\n",
    "    cams = [cam1_ext, cam2_ext]\n",
    "\n",
    "    fixed_camera_origin_direction = [np.zeros(12) for i in cams]\n",
    "    for j, ext_cam in enumerate(cams):\n",
    "        # ray = Tools.reproject_ray(camera_intrinsic, ext_cam, (960, 540))\n",
    "        fixed_camera_origin_direction[j][:3] = ext_cam[:3, 3]\n",
    "        # fixed_camera_origin_direction[j][3:] = ray[1]\n",
    "        dir_x, dir_y, dir_z = np.array([1, 0, 0, 1]), np.array([0, 1, 0, 1]), np.array([0, 0, 1, 1])\n",
    "        fixed_camera_origin_direction[j][3:6] = ext_cam.dot(dir_x)[:3]\n",
    "        fixed_camera_origin_direction[j][6:9] = ext_cam.dot(dir_y)[:3]\n",
    "        fixed_camera_origin_direction[j][9:12] = ext_cam.dot(dir_z)[:3]\n",
    "    fixed_camera_origin_direction = np.array(fixed_camera_origin_direction)\n",
    "\n",
    "    ax = plt.figure(figsize=(15, 10)).add_subplot(projection='3d')\n",
    "\n",
    "    color = [\"r\", \"g\", \"b\"]\n",
    "    # training - scatter pt and cam\n",
    "    ax.scatter(xs=pt3d[:, 0], ys=pt3d[:, 1], zs=pt3d[:, 2], zdir='y', label='Known pts', c='magenta')\n",
    "    ax.scatter(xs=fixed_camera_origin_direction[:, :3][:, 0], ys=fixed_camera_origin_direction[:, :3][:, 1], zs=fixed_camera_origin_direction[:, :3][:, 2], zdir='y', label='Known camera', c='g')\n",
    "\n",
    "    # known - plot cam\n",
    "    for cam_data_fixed in fixed_camera_origin_direction:\n",
    "        for k_idx, k in enumerate(cam_data_fixed[3:].reshape(3, 3)):\n",
    "            start = cam_data_fixed[:3]\n",
    "            end = k / np.linalg.norm(k - start)# / np.linalg.norm(k)#cam_data[:3] + cam_data[3:]\n",
    "            # end = cam_data[:3] + cam_data[3:6]\n",
    "            poses = np.array([start, end]).reshape(-1, 3)\n",
    "            ax.plot(xs=poses[:, 0], ys=poses[:, 1], zs=poses[:, 2], zdir=\"y\", c=color[k_idx])\n",
    "\n",
    "    ax.view_init(elev=45., azim=-45, roll=0)\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Z\")\n",
    "    ax.set_zlabel(\"Y\")\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-1, 5)\n",
    "    ax.set_zlim(0, 5)\n",
    "\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_generate_route_from_data_manager = True\n",
    "\n",
    "route = {}\n",
    "if is_generate_route_from_data_manager:\n",
    "    route = Tools_BundleAdjustment.predict_route(data_manager)\n",
    "else:\n",
    "    # load directly from file correspondences\n",
    "    img_idx = np.array([int(os.path.basename(i).split(\".\")[0]) for i in glob.glob(os.path.join(dataset_info[\"data\"][\"image\"], \"*.jpg\"))])\n",
    "    img_idx = sorted(img_idx)\n",
    "    extrinsics_from_essential = {}\n",
    "\n",
    "    start_idx = 0\n",
    "    for i, img_name_l in enumerate(img_idx[start_idx:-1]):\n",
    "        p1, p2 = [], []\n",
    "        img_name_r = img_idx[start_idx + i + 1]\n",
    "        corr_l_exist, corr_r_exist, corr_exist = utils.is_correspondence_exist(PROJECT_DIR, dataset_name, img_name_l, img_name_r)\n",
    "        correspondences_path = \"\"\n",
    "        if corr_exist:\n",
    "            if corr_l_exist:\n",
    "                correspondences_path = os.path.join(dataset_info[\"data\"][\"correspondence\"], f\"{img_name_l}_{img_name_r}.txt\")\n",
    "                corr_data = utils.read_txt(correspondences_path)\n",
    "                for k, corr in enumerate(corr_data):\n",
    "                    p1_x, p1_y, p2_x, p2_y = np.array(corr.rstrip().split(\" \")).astype(float)\n",
    "                    p1.append([p1_x, p1_y])\n",
    "                    p2.append([p2_x, p2_y])\n",
    "            elif corr_r_exist:\n",
    "                correspondences_path = os.path.join(dataset_info[\"data\"][\"correspondence\"], f\"{img_name_r}_{img_name_l}.txt\")\n",
    "                corr_data = utils.read_txt(correspondences_path)\n",
    "                for k, corr in enumerate(corr_data):\n",
    "                    p2_x, p2_y, p1_x, p1_y = np.array(corr.rstrip().split(\" \")).astype(float)\n",
    "                    p1.append([p1_x, p1_y])\n",
    "                    p2.append([p2_x, p2_y])\n",
    "        p1 = np.array(p1)\n",
    "        p2 = np.array(p2)\n",
    "        \n",
    "        new_ext = Tools_BundleAdjustment.estimate_essentials(data_manager.camera_intrinsic, p1, p2)\n",
    "\n",
    "        extrinsics_from_essential[str([start_idx + i, start_idx + i+1])] = new_ext\n",
    "        route = extrinsics_from_essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "from scipy.optimize import least_squares, Bounds\n",
    "import time\n",
    "\n",
    "class BundleAdjustment:\n",
    "    def __init__(self, data_manager: DataManager, sequence_essentials: dict, start_cam=0):\n",
    "        self.data_manager = data_manager\n",
    "        self.sequence_essentials = sequence_essentials\n",
    "        self.start_cam = start_cam\n",
    "        self.known_extrinsics = {start_cam: np.eye(4)}\n",
    "        self.known_3d_points = {}\n",
    "        self.exclude_triangulation = {} #{\"[cam_from, cam_to]\": [idxs]}\n",
    "        self.cam_from = 0\n",
    "        self.counter = -1\n",
    "        self.interval = 250\n",
    "        self.max_num_camera_each_loop = 5\n",
    "\n",
    "    def run(self, iteration_idx=0):\n",
    "        # default parameters\n",
    "        n_params_camera = 6\n",
    "        n_params_point = 3\n",
    "        route = list(self.sequence_essentials.keys())\n",
    "        _, camera_indices, point_indices, points_2d, _, _, camera_intrinsic = self.data_manager.get()\n",
    "        \n",
    "\n",
    "        for step in range(2):\n",
    "        # if True:\n",
    "            # step = 0\n",
    "            # first one for the 2 camera iteration, second for all cameras refinemenet\n",
    "\n",
    "            points_ids = [] #store intersection point indexes\n",
    "            camera_ids = [] #store camera indexes to train\n",
    "            \n",
    "            if (step == 0):\n",
    "                # 1st step: calibrate only using 2 cameras. define number of cameras and points\n",
    "                # find the same points between two cameras \n",
    "                print(f\" ----- Start iteration {iteration_idx}, camera pair: {route[iteration_idx]} ----- \")\n",
    "                cam_from, cam_to = np.array(route[iteration_idx][1:-1].split(\",\"), dtype=int)\n",
    "                self.cam_from = cam_from\n",
    "                its = self.data_manager.find_same_points_idx(cam_from, cam_to)\n",
    "                camera_ids = [cam_from, cam_to]\n",
    "                points_ids = its\n",
    "            elif (step == 1):\n",
    "                # if ((iteration_idx - 1) % 4 != 0):\n",
    "                #     continue\n",
    "                \n",
    "                # 2nd step: refine all cameras\n",
    "                print(f\" ----- Refine cameras and points, camera pairs: {list(self.known_extrinsics.keys())} ----- \")\n",
    "                # check known cameras, and known points\n",
    "                if not len(self.known_extrinsics.keys()) % self.max_num_camera_each_loop == 0:\n",
    "                    camera_ids = list(self.known_extrinsics.keys())[-self.max_num_camera_each_loop:]\n",
    "                else:\n",
    "                    camera_ids = list(self.known_extrinsics.keys())\n",
    "                points_ids = list(self.known_3d_points.keys())\n",
    "                self.cam_from = camera_ids[0]\n",
    "                # self.cam_from = self.start_cam\n",
    "            else:\n",
    "                print(f\"Step{step} not known!\")\n",
    "\n",
    "            # loop over indices to fill the arrays\n",
    "            camera_indices_filter = []\n",
    "            point_indices_filter = []\n",
    "            points_2d_filter = []\n",
    "            points_3d_filter = []\n",
    "            for cam, pt, pt2 in zip(camera_indices, point_indices, points_2d):\n",
    "                if (pt in points_ids) and (cam in camera_ids):\n",
    "                    # exclude marked point\n",
    "                    if (cam in list(self.exclude_triangulation.keys())):\n",
    "                        if (pt in list(self.exclude_triangulation[cam])):\n",
    "                            continue\n",
    "                    camera_indices_filter.append(cam)\n",
    "                    point_indices_filter.append(pt)\n",
    "                    points_2d_filter.append(pt2)\n",
    "            camera_indices_filter = np.array(camera_indices_filter)\n",
    "            point_indices_filter = np.array(point_indices_filter)\n",
    "            points_2d_filter = np.array(points_2d_filter)\n",
    "            points_3d_filter = np.array(points_3d_filter)\n",
    "\n",
    "            # change the point indices into different id (for training and conversion later)\n",
    "            # create mapping dictionary\n",
    "            unique_points_id_sorted = np.unique(point_indices_filter)\n",
    "            unique_points_mapping_dict = dict([(k, v) for k, v in zip(unique_points_id_sorted, np.arange(len(unique_points_id_sorted)))])\n",
    "            unique_points_mapping_dict_reverse = dict([(v, k) for k, v in unique_points_mapping_dict.items()])\n",
    "            point_indices_filter_2 = np.copy(point_indices_filter)\n",
    "            for k, v in unique_points_mapping_dict.items(): point_indices_filter_2[point_indices_filter==k] = v\n",
    "\n",
    "            # change the camera indices too\n",
    "            unique_camera_id_sorted = np.unique(camera_indices_filter)\n",
    "            unique_camera_mapping_dict = dict([(k, v) for k, v in zip(unique_camera_id_sorted, np.arange(len(unique_camera_id_sorted)))])\n",
    "            unique_camera_mapping_dict_reverse = dict([(v, k) for k, v in unique_camera_mapping_dict.items()])\n",
    "            camera_indices_filter_2 = np.copy(camera_indices_filter)\n",
    "            for k, v in unique_camera_mapping_dict.items(): camera_indices_filter_2[camera_indices_filter==k] = v\n",
    "\n",
    "            #  ---- fixed! ---\n",
    "\n",
    "            # and the rest\n",
    "            camera_extrinsics_filter = [] #0th camera as default\n",
    "            points_3d_filter = np.random.random((len(unique_points_id_sorted), 3))\n",
    "            if (step == 0):\n",
    "                # calibrate the 3d points, if the points has been intersected before,\n",
    "                # put it directly into the array\n",
    "                cam_from, cam_to = np.array(route[iteration_idx][1:-1].split(\",\"), dtype=int)\n",
    "\n",
    "                # NEW Camera! only 2 cameras calibration\n",
    "                # new_extrinsics = self.sequence_essentials[route[iteration_idx]].copy().dot(self.known_extrinsics[cam_from].copy())\n",
    "                new_extrinsics = self.known_extrinsics[cam_from].dot(self.sequence_essentials[route[iteration_idx]])\n",
    "                camera_extrinsics_filter.append(self.known_extrinsics[cam_from])\n",
    "                camera_extrinsics_filter.append(new_extrinsics)\n",
    "\n",
    "                # find same points between two image index\n",
    "                # its = list(unique_points_id_sorted)#self.data_manager.find_same_points_idx(cam_from, cam_to)\n",
    "                its = self.data_manager.find_same_points_idx(cam_from, cam_to)\n",
    "                \n",
    "                its_known = list(set(its) & set(list(self.known_3d_points.keys())))\n",
    "                for i in its_known:\n",
    "                    # find its index (idx) on the current dict \n",
    "                    # print(i, \"\\n\", its, \"\\n\", its_known, \"\\n\", unique_points_mapping_dict)\n",
    "                    # TODO: For every known 3d points, map it wrt the cam_from since we will apply it \n",
    "                    idx = unique_points_mapping_dict[i] #get arange index\n",
    "\n",
    "                    # transform the known homogenous point\n",
    "                    # points_3d_filter[idx] = Tools_BundleAdjustment.remap_point_3d(self.known_extrinsics[0], new_extrinsics, self.known_3d_points[i].copy())[:3]\n",
    "                    points_3d_filter[idx] = self.known_3d_points[i][\"pos\"].copy()\n",
    "                \n",
    "                # look into the intersections that is now known, find the index that is not known from its\n",
    "                its_not_known = list(set(its) - set(self.known_3d_points.keys()))\n",
    "                idx_not_known_from_its = [unique_points_mapping_dict[i] for i in its_not_known]\n",
    "                # idx_not_known_from_its = [its.index(i) for i in its_not_known]\n",
    "\n",
    "                if len(idx_not_known_from_its) > 0:\n",
    "                    # store uv and 3d points\n",
    "                    uv_src, uv_tar = self.data_manager.find_same_points_2d(cam_from, cam_to)    \n",
    "                    uv_src, uv_tar = uv_src[idx_not_known_from_its], uv_tar[idx_not_known_from_its]\n",
    "                    pts_3d = Tools.generate_3d_from_2_cameras(cam_int=camera_intrinsic, \n",
    "                                                            cam_ext_src=self.known_extrinsics[cam_from],\n",
    "                                                            cam_ext_tar=new_extrinsics,\n",
    "                                                            uv_src=uv_src,\n",
    "                                                            uv_tar=uv_tar)[0]\n",
    "\n",
    "                    # store points 3d filter\n",
    "                    # points_3d_filter = pts_3d\n",
    "                    points_3d_filter[idx_not_known_from_its] = pts_3d\n",
    "\n",
    "            elif (step == 1):\n",
    "                # combine all existing extrinsics\n",
    "                camera_extrinsics_filter = np.array([self.known_extrinsics[idx] for idx in unique_camera_id_sorted])\n",
    "                # camera_extrinsics_filter = np.array([list(self.known_extrinsics.values())])\n",
    "\n",
    "                # get all known 3d points\n",
    "                # points_3d_filter = np.array([self.known_3d_points[idx] for idx in unique_points_id_sorted])\n",
    "                points_3d_filter = np.array([self.known_3d_points[idx][\"pos\"] for idx in unique_points_id_sorted])\n",
    "                \n",
    "\n",
    "            # count number of observations\n",
    "            # number of camera always -1 since we assume that the first camera extrinsics is identity\n",
    "            # ignore it for now\n",
    "            n_cameras = len(unique_camera_id_sorted)\n",
    "            n_points = len(unique_points_id_sorted)\n",
    "            n_observation = 2 * len(point_indices_filter_2)\n",
    "            n_variable = n_params_camera * n_cameras + n_params_point * n_points\n",
    "            print(f\" using {n_cameras} cameras and {n_points} points\")\n",
    "\n",
    "            # --- start build sparsity matrix ---\n",
    "            A = lil_matrix((n_observation, n_variable), dtype=float)\n",
    "\n",
    "            # fill the matrix with ones\n",
    "            i = np.arange(int(0.5 * n_observation))\n",
    "            for s in range(6):\n",
    "                A[2 * i,     camera_indices_filter_2 * n_params_camera + s] = 1\n",
    "                A[2 * i + 1, camera_indices_filter_2 * n_params_camera + s] = 1\n",
    "\n",
    "            for s in range(3):\n",
    "                A[2 * i,     n_cameras * n_params_camera + point_indices_filter_2 * n_params_point + s] = 1\n",
    "                A[2 * i + 1, n_cameras * n_params_camera + point_indices_filter_2 * n_params_point + s] = 1\n",
    "            # --- end build sparsity matrix ---\n",
    "\n",
    "            # --- build input x ---\n",
    "            x = []\n",
    "            \n",
    "            camera_extrinsics_filter = np.array(camera_extrinsics_filter)\n",
    "            points_3d_filter = np.array(points_3d_filter)\n",
    "            for cam_ext in camera_extrinsics_filter:\n",
    "                pos = cam_ext[:3, 3]\n",
    "                rot = Tools.rotation_matrix_to_rodriguez(cam_ext[:3, :3])\n",
    "                x.extend(pos)\n",
    "                x.extend(rot)      \n",
    "            for pt in points_3d_filter:\n",
    "                x.extend(pt)\n",
    "            # --- end build input x ---\n",
    "            # print(len(x), n_cameras, n_points, n_observation, n_variable)\n",
    "            # print(len(camera_extrinsics_filter), camera_extrinsics_filter)\n",
    "            # print(len(points_3d_filter), points_3d_filter)\n",
    "            \n",
    "            # --- build trainer ---\n",
    "            t0 = time.time()\n",
    "            #jac=\"3-point\", xtol=1e-5, gtol=1e-5\n",
    "            ftol_value = 1e-4 #if n_cameras == 2 else 1e-5\n",
    "            res = least_squares(self._fun, x, jac_sparsity=A, verbose=2, x_scale='jac', ftol=ftol_value, method='dogbox', loss=\"soft_l1\",\n",
    "                                args=(n_cameras, n_points, camera_intrinsic, camera_indices_filter_2, point_indices_filter_2, \n",
    "                                      points_2d_filter))\n",
    "            t1 = time.time()\n",
    "            print(f\" done in {t1-t0}s\")\n",
    "            # --- end trainer ---\n",
    "\n",
    "            # --- store data ---\n",
    "            params = res.x\n",
    "            cam_params = params[:n_cameras * 6].reshape((n_cameras, 6))\n",
    "            points_3d = params[n_cameras * 6:].reshape((n_points, 3))\n",
    "            if (step == 0):\n",
    "                # # extract idx, just two of them\n",
    "                cam_from, cam_to = unique_camera_id_sorted\n",
    "                # # multiply ext result with stored camera extrinsics of the reference image (left)\n",
    "                # cam_mat = np.eye(4)\n",
    "                # cam_mat[:3, 3] = cam_params[1][:3]\n",
    "                # cam_mat[:3, :3] = Tools.rodriguez_to_rotation_matrix(cam_params[1][3:])\n",
    "                # self.known_extrinsics[cam_to] = cam_mat.dot(self.known_extrinsics[cam_from])\n",
    "                for cam, id in zip(cam_params, unique_camera_id_sorted):\n",
    "                    cam_mat = np.eye(4)\n",
    "                    cam_mat[:3, 3] = cam[:3]\n",
    "                    cam_mat[:3, :3] = Tools.rodriguez_to_rotation_matrix(cam[3:])\n",
    "                    self.known_extrinsics[id] = cam_mat\n",
    "\n",
    "                # add outlier rejection system\n",
    "                uvs_gt = self.data_manager.find_same_points_2d(cam_from, cam_to)\n",
    "                _, dists = Tools.generate_3d_from_2_cameras(camera_intrinsic, self.known_extrinsics[cam_from], self.known_extrinsics[cam_to], uvs_gt[0], uvs_gt[1], include_dist=True)  \n",
    "                dists_sorted = np.sort(dists)\n",
    "                \n",
    "                # ratio = 0.5\n",
    "                ratio = (1.58 - 0.0036 * len(points_3d))\n",
    "                ratio = max(min(0.9, ratio), 0.5)\n",
    "                limit = min(np.average(dists_sorted), dists_sorted[int(ratio * len(dists_sorted))])\n",
    "                bool_outlier = dists > limit\n",
    "\n",
    "                for pt_idx, (pt_3d, is_outlier) in enumerate(zip(points_3d, bool_outlier)):\n",
    "                    # get true point index from the dict\n",
    "                    true_pt_idx = unique_points_mapping_dict_reverse[pt_idx]\n",
    "\n",
    "                    # skipping the outlier for the refinement in the 2nd step\n",
    "                    if is_outlier:\n",
    "                        c = cam_from\n",
    "                        if c not in self.exclude_triangulation.keys():\n",
    "                            self.exclude_triangulation[c] = []\n",
    "                        self.exclude_triangulation[c].append(true_pt_idx)\n",
    "                        print(f\"skip a {pt_idx}, dists {dists[pt_idx]}\")\n",
    "                        continue\n",
    "\n",
    "                    # self.known_3d_points[true_pt_idx] = pt_3d[:3]  \n",
    "                    if true_pt_idx in list(self.known_3d_points.keys()):\n",
    "                        # compare the distance before saving\n",
    "                        if dists[pt_idx] < self.known_3d_points[true_pt_idx][\"dist\"]:\n",
    "                            self.known_3d_points[true_pt_idx] = {\n",
    "                                \"pos\": pt_3d[:3], \"dist\": dists[pt_idx]\n",
    "                            }\n",
    "                        else:\n",
    "                            # skip saving the point if the new distance is larger\n",
    "                            continue\n",
    "                    else:                        \n",
    "                        self.known_3d_points[true_pt_idx] = {\n",
    "                            \"pos\": pt_3d[:3], \"dist\": dists[pt_idx]\n",
    "                        }\n",
    "\n",
    "            elif (step == 1):\n",
    "                # just save it\n",
    "                # for cam_idx, cam_param in zip(unique_camera_id_sorted, cam_params): #ignore 0th\n",
    "                for cam_idx, cam_param in enumerate(cam_params): #ignore 0th\n",
    "                    cam_mat = np.eye(4)\n",
    "                    cam_mat[:3, 3] = cam_param[:3]\n",
    "                    cam_mat[:3, :3] = Tools.rodriguez_to_rotation_matrix(cam_param[3:])\n",
    "                    self.known_extrinsics[unique_camera_mapping_dict_reverse[cam_idx]] = cam_mat\n",
    "                \n",
    "                # readjust known 3d points entirely\n",
    "                cam_ext_indexes = list(self.known_extrinsics.keys())\n",
    "                for cam_from_idx in range(len(cam_ext_indexes) - 1):\n",
    "                    c_from, c_to = cam_ext_indexes[cam_from_idx], cam_ext_indexes[cam_from_idx + 1]\n",
    "                    its = self.data_manager.find_same_points_idx(c_from, c_to)\n",
    "                    pts_2d_from, pts_2d_to = self.data_manager.find_same_points_2d(c_from, c_to)\n",
    "                    pts_3d_new, dists = Tools.generate_3d_from_2_cameras(camera_intrinsic, self.known_extrinsics[c_from], self.known_extrinsics[c_to], pts_2d_from, pts_2d_to, include_dist=True)  \n",
    "\n",
    "                    for (k, pt_3d, dist) in zip(its, pts_3d_new, dists):\n",
    "                        if k in self.exclude_triangulation[c_from]:\n",
    "                            # skip if the point is marked before to not included\n",
    "                            continue\n",
    "\n",
    "                        # save the point and distance\n",
    "                        self.known_3d_points[k] = {\n",
    "                            \"pos\": pt_3d[:3], \"dist\": dist\n",
    "                        }\n",
    "\n",
    "\n",
    "                # for pt_idx, pt_3d in enumerate(points_3d):\n",
    "                #     # if np.linalg.norm(pt_3d) > 10:\n",
    "                #     #     print(f\"skip b {pt_idx}\")\n",
    "                #     #     continue\n",
    "                #     true_pt_idx = unique_points_mapping_dict_reverse[pt_idx]\n",
    "                #     self.known_3d_points[true_pt_idx] = pt_3d[:3]\n",
    "\n",
    "        # --- end store data ---\n",
    "        return res, (t1-t0)\n",
    "\n",
    "    def _fun(self, params, n_cameras, n_points, camera_intrinsic, camera_indices, point_indices, points_2d):\n",
    "        \"Compute residual (error) projection for each observation\"\n",
    "        # extract camera parameters\n",
    "        cam_params = params[:n_cameras * 6].reshape((n_cameras, 6))\n",
    "        points_3d = params[n_cameras * 6:].reshape((n_points, 3))\n",
    "\n",
    "        # save record\n",
    "        self.counter += 1\n",
    "        self.counter = self.counter % self.interval\n",
    "        save_record = True\n",
    "        if save_record and (self.counter == 0):\n",
    "            # print(self.counter, self.data_manager.quick_save_record_idx, self.data_manager.quick_save_campts_rec|ord_idx)\n",
    "            rec = [len(cam_params), len(points_3d)]\n",
    "            rec.extend(params)\n",
    "            self.data_manager.quick_save_data(str(rec), run_idx)\n",
    "            self.data_manager.quick_save_camera_and_pts3d({\n",
    "                \"camera\": [list(i.flatten()) for i in self.known_extrinsics.values()],\n",
    "                \"pts\": [list(i[\"pos\"]) for i in self.known_3d_points.values()]\n",
    "            }, run_idx)\n",
    "\n",
    "        ratio_distance = 1    \n",
    "        # if self.cam_from == 0:\n",
    "        #     # it means full adjustment\n",
    "        #     ratio_distance = np.linalg.norm(cam_params[1][:3])\n",
    "        # else:\n",
    "            # only two cameras\n",
    "            # ratio_distance = 1 / np.linalg.norm(cam_params[1][:3] - self.known_extrinsics[self.cam_from][:3, 3])\n",
    "        cam_extrinsics = [self.known_extrinsics[self.cam_from]] # always ignore the 0th camera \n",
    "        # cam_extrinsics = [] # not ignore the 0th camera \n",
    "        for cam in cam_params[1:]:\n",
    "            cam_mat = np.eye(4)\n",
    "            cam_mat[:3, 3] = cam[:3] * ratio_distance\n",
    "            cam_mat[:3, :3] = Tools.rodriguez_to_rotation_matrix(cam[3:])\n",
    "            cam_extrinsics.append(cam_mat)\n",
    "\n",
    "\n",
    "        uvs = []\n",
    "        for cam_idx, pt_idx in zip(camera_indices, point_indices):\n",
    "            # try reiterate the point (maybe it works? dunno)\n",
    "            # xs, ys, zs = [-10, 10], [-10, 10], [-10, 10]\n",
    "            # if ((points_3d[pt_idx][0] < xs[0]) or (points_3d[pt_idx][0] > xs[1])) or \\\n",
    "            #     ((points_3d[pt_idx][1] < ys[0]) or (points_3d[pt_idx][1] > ys[1])) or \\\n",
    "            #     ((points_3d[pt_idx][2] < zs[0]) or (points_3d[pt_idx][2] > zs[1])):\n",
    "            #     points_3d[pt_idx] = np.random.uniform(low=-10, high=10, size=(3))\n",
    "\n",
    "            uv = Tools.reproject_uv(cam_intrinsic=camera_intrinsic, \n",
    "                               cam_extrinsic=cam_extrinsics[cam_idx],\n",
    "                               pt_3d=points_3d[pt_idx],\n",
    "                               is_extrinsic_inverted=False)\n",
    "            uvs.append(uv)\n",
    "        # uvs = np.array(uvs).astype(int)\n",
    "        # points_2d = points_2d.astype(int)\n",
    "        diff = np.abs(uvs - points_2d).ravel()\n",
    "        # for i, (uv1, uv2) in enumerate(zip(uvs, points_2d)):\n",
    "        #     if i > 3: \n",
    "        #         break\n",
    "        #     print(uv1, uv2, diff.reshape(-1, 2)[i], diff.sum(), points_3d[i])\n",
    "        # print()\n",
    "        return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx_ba = 0\n",
    "run_idx = 2\n",
    "data_manager.quick_save_reset()\n",
    "bundle_adjust = BundleAdjustment(data_manager, route, start_idx_ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bundle_adjust.known_extrinsics.keys())-1 + start_idx, len(route) + start_idx):\n",
    "# for i in range(start_idx_ba, len(route) + start_idx_ba):\n",
    "# for i in range(start_idx_ba, 6 + start_idx_ba):\n",
    "    res = bundle_adjust.run(i)\n",
    "\n",
    "    # save data\n",
    "    dataset_path = dataset_info[\"data\"][\"path\"]\n",
    "    new_known_3d_points = {}\n",
    "    for k, v in bundle_adjust.known_3d_points.items():\n",
    "        new_known_3d_points[f\"p{k}\"] = v#list(v)\n",
    "        new_known_3d_points[f\"p{k}\"][\"pos\"] = list(new_known_3d_points[f\"p{k}\"][\"pos\"])\n",
    "    utils.export_json(f\"{dataset_path}/result/run{run_idx}/known_3d_points_{i}.json\", new_known_3d_points)\n",
    "\n",
    "    new_known_extrinsics = {}\n",
    "    for k, v in bundle_adjust.known_extrinsics.items():\n",
    "        new_known_extrinsics[f\"i{data_camera_id[k][1]}\"] = list(v.flatten())\n",
    "    utils.export_json(f\"{dataset_path}/result/run{run_idx}/known_camera_extrinsics_{i}.json\", new_known_extrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
