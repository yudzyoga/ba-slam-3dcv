{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.auto_scroll_threshold = 9999;\n\n# Enable autoreloading if import packages are changed\n%load_ext autoreload\n%autoreload 2\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;\n",
    "\n",
    "# Enable autoreloading if import packages are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "PROJECT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.utils import utils\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "from src.eval import chamfer_distance, crop_points_to_bbox, \\\n",
    "    compute_transformation_error, pose_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using eval.py (stage 1)\n",
    "The commands below are the same as the provided eval.py's `main()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"box_v4_stage1\"\n",
    "dataset_info = utils.get_dataset_info(dataset_name, PROJECT_DIR)\n",
    "dataset_info[\"data\"]\n",
    "\n",
    "f_gt = open(os.path.join(dataset_info[\"data\"][\"path\"], \"gt_camera_parameters.json\"), \"r\")\n",
    "camera_param_gt = json.load(f_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation error: 2.12\n",
      "Translation error: 6.574\n",
      "Chamfer distance between pointclouds: 0.7185401029350127\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-8\n",
    "\n",
    "f_gt = open(os.path.join(dataset_info[\"data\"][\"path\"], \"gt_camera_parameters.json\"), \"r\")\n",
    "f_predicted = open(os.path.join(dataset_info[\"data\"][\"path\"], \"estimated_camera_parameters.json\"), \"r\")\n",
    "\n",
    "camera_param_gt = json.load(f_gt)\n",
    "camera_param_predicted = json.load(f_predicted)\n",
    "\n",
    "scale = 0\n",
    "cameras = camera_param_gt[\"extrinsics\"].keys()\n",
    "for camera in cameras:\n",
    "    if camera == \"00000.jpg\":\n",
    "        continue\n",
    "\n",
    "    predicted_camera1 = np.array(camera_param_predicted[\"extrinsics\"][camera])\n",
    "    predicted_camera2 = np.array(camera_param_gt[\"extrinsics\"][camera])\n",
    "    scale += (np.linalg.norm(predicted_camera1[:3, 3]) / (np.linalg.norm(predicted_camera2[:3, 3] + eps)))\n",
    "\n",
    "scale /= (len(cameras) - 1)\n",
    "\n",
    "pcd_gt = trimesh.load(os.path.join(dataset_info[\"data\"][\"path\"], \"gt_points.ply\"))\n",
    "gt_points = np.array(pcd_gt.vertices, dtype = np.float32)\n",
    "\n",
    "pcd_test = trimesh.load(os.path.join(dataset_info[\"data\"][\"path\"], \"estimated_points.ply\")) # Give path to your .ply here (as above)\n",
    "test_points = np.array(pcd_test.vertices, dtype = np.float32) / scale\n",
    "\n",
    "bb = [\n",
    "    np.array([-4.523355, -1.264923,  0.198537]), \n",
    "    np.array([4.976645, 2.235077, 9.698537])\n",
    "] # Only for box evaluation, do not change\n",
    "\n",
    "gt_points = crop_points_to_bbox(gt_points, bb)\n",
    "test_points = crop_points_to_bbox(test_points, bb)\n",
    "rotation_error, translation_error = pose_estimate(camera_param_gt[\"extrinsics\"], camera_param_predicted[\"extrinsics\"], scale)\n",
    "\n",
    "print(\"Rotation error:\", round(rotation_error, 2))\n",
    "print(\"Translation error:\", round(translation_error, 3))\n",
    "print(\"Chamfer distance between pointclouds:\", chamfer_distance(gt_points, test_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using eval.py (stage 2)\n",
    "The commands below are the same as the provided eval.py's `main()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/home/yudzyoga/Documents/Courses/2ndSemester/3DCV/Assignments/github/3dcv_group_10/Project/Submission/dataset/milk_stage2',\n",
       " 'image': '/home/yudzyoga/Documents/Courses/2ndSemester/3DCV/Assignments/github/3dcv_group_10/Project/Submission/dataset/milk_stage2/images',\n",
       " 'correspondence': '/home/yudzyoga/Documents/Courses/2ndSemester/3DCV/Assignments/github/3dcv_group_10/Project/Submission/dataset/milk_stage2/correspondences'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"milk_stage2\"\n",
    "dataset_info = utils.get_dataset_info(dataset_name, PROJECT_DIR)\n",
    "dataset_info[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation error: 1.37\n",
      "Translation error: 0.444\n"
     ]
    }
   ],
   "source": [
    "def mesh_error(mesh, mesh_points, test_points, num_points):\n",
    "    tree = KDTree(test_points)\n",
    "    dist_mesh_points = tree.query(mesh_points)[0]\n",
    "\n",
    "    dist_points_mesh = trimesh.proximity.closest_point(mesh, test_points)[1]\n",
    "\n",
    "    return 0.5 * (np.mean(dist_points_mesh) + np.mean(dist_mesh_points))\n",
    "\n",
    "eps = 1e-8\n",
    "\n",
    "f_gt = open(os.path.join(dataset_info[\"data\"][\"path\"], \"gt_camera_parameters.json\"), \"r\")\n",
    "f_predicted = open(os.path.join(dataset_info[\"data\"][\"path\"], \"estimated_camera_parameters.json\"), \"r\")\n",
    "\n",
    "# f_gt = open(\"milk/gt_camera_parameters.json\", \"r\")\n",
    "# f_predicted = open(\"milk/estimated_camera_parameters.json\", \"r\")\n",
    "\n",
    "num_points_sample = 1000\n",
    "\n",
    "camera_param_gt = json.load(f_gt)\n",
    "camera_param_predicted = json.load(f_predicted)\n",
    "\n",
    "scale = 0\n",
    "cameras = camera_param_gt[\"extrinsics\"].keys()\n",
    "for camera in cameras:\n",
    "    if camera == \"00000.jpg\":\n",
    "        continue\n",
    "\n",
    "    predicted_camera1 = np.array(camera_param_predicted[\"extrinsics\"][camera])\n",
    "    predicted_camera2 = np.array(camera_param_gt[\"extrinsics\"][camera])\n",
    "\n",
    "    scale += (np.linalg.norm(predicted_camera1[:3, 3]) / (np.linalg.norm(predicted_camera2[:3, 3] + eps)))\n",
    "scale /= (len(cameras) - 1)\n",
    "\n",
    "\n",
    "# mesh_gt = trimesh.load(\"milk/gt_mesh.ply\")\n",
    "mesh_gt = trimesh.load(os.path.join(dataset_info[\"data\"][\"path\"], \"gt_mesh.ply\"))\n",
    "gt_points = trimesh.sample.sample_surface_even(mesh_gt, num_points_sample, seed = 42)[0]\n",
    "\n",
    "# pcd_test = trimesh.load(\"milk/estimated_points.ply\") # Give path to your .ply here (as above)\n",
    "pcd_test = trimesh.load(os.path.join(dataset_info[\"data\"][\"path\"], \"estimated_points.ply\"))\n",
    "test_points = np.array(pcd_test.vertices, dtype = np.float32) / scale\n",
    "\n",
    "bb = [\n",
    "        np.array([-0.5, -0.15,  0.1]), \n",
    "        np.array([0.5, 0.4, 1.1])\n",
    "    ] # Only for milk evaluation, do not change\n",
    "\n",
    "test_points = crop_points_to_bbox(test_points, bb)\n",
    "\n",
    "rotation_error, translation_error = pose_estimate(camera_param_gt[\"extrinsics\"], camera_param_predicted[\"extrinsics\"], scale)\n",
    "\n",
    "print(\"Rotation error:\", round(rotation_error, 2))\n",
    "print(\"Translation error:\", round(translation_error, 3))\n",
    "# print(\"Mesh error:\", mesh_error(mesh_gt, gt_points, test_points, num_points_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
